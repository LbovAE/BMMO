{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9d949fc3f1bb4624adf1b97f6ef01dea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2aa39c8b6d984c00bccb543223679741",
              "IPY_MODEL_f138ca271a7a43b6b1ad26922c059289",
              "IPY_MODEL_b81e4a61a98145f4b9096b3bba7b62fd"
            ],
            "layout": "IPY_MODEL_bd987978bdc34d56b004fd3575f01f14"
          }
        },
        "2aa39c8b6d984c00bccb543223679741": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_931e16dd3eb0426b914d72bc2480de83",
            "placeholder": "​",
            "style": "IPY_MODEL_2db6adce78934e0e9bb6b4c1157e9603",
            "value": "100%"
          }
        },
        "f138ca271a7a43b6b1ad26922c059289": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd712e7ea6984d5382756d368d77a599",
            "max": 5000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_516fa8700cc34bb0b9df44b2db0d0768",
            "value": 5000
          }
        },
        "b81e4a61a98145f4b9096b3bba7b62fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c723a55c9af343b3bcc30fe0ca6f8211",
            "placeholder": "​",
            "style": "IPY_MODEL_658fd08515d74c14992a78b3fb96b362",
            "value": " 5000/5000 [34:31&lt;00:00,  2.28it/s]"
          }
        },
        "bd987978bdc34d56b004fd3575f01f14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "931e16dd3eb0426b914d72bc2480de83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2db6adce78934e0e9bb6b4c1157e9603": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dd712e7ea6984d5382756d368d77a599": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "516fa8700cc34bb0b9df44b2db0d0768": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c723a55c9af343b3bcc30fe0ca6f8211": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "658fd08515d74c14992a78b3fb96b362": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-ema\n",
        "!pip install denoising-diffusion-pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfYFnbRspT0m",
        "outputId": "1472ba9f-4722-476f-8531-6a321bd25976"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch-ema in /usr/local/lib/python3.10/dist-packages (0.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torch-ema) (2.5.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torch-ema) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->torch-ema) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torch-ema) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torch-ema) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->torch-ema) (2024.6.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->torch-ema) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->torch-ema) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torch-ema) (3.0.2)\n",
            "Requirement already satisfied: denoising-diffusion-pytorch in /usr/local/lib/python3.10/dist-packages (2.1.1)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from denoising-diffusion-pytorch) (0.34.2)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from denoising-diffusion-pytorch) (0.8.0)\n",
            "Requirement already satisfied: ema-pytorch>=0.4.2 in /usr/local/lib/python3.10/dist-packages (from denoising-diffusion-pytorch) (0.7.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from denoising-diffusion-pytorch) (1.26.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from denoising-diffusion-pytorch) (10.4.0)\n",
            "Requirement already satisfied: pytorch-fid in /usr/local/lib/python3.10/dist-packages (from denoising-diffusion-pytorch) (0.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from denoising-diffusion-pytorch) (1.13.1)\n",
            "Requirement already satisfied: torch>=2.0 in /usr/local/lib/python3.10/dist-packages (from denoising-diffusion-pytorch) (2.5.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from denoising-diffusion-pytorch) (0.20.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from denoising-diffusion-pytorch) (4.66.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->denoising-diffusion-pytorch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->denoising-diffusion-pytorch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->denoising-diffusion-pytorch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->denoising-diffusion-pytorch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->denoising-diffusion-pytorch) (2024.6.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->denoising-diffusion-pytorch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.0->denoising-diffusion-pytorch) (1.3.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate->denoising-diffusion-pytorch) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate->denoising-diffusion-pytorch) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate->denoising-diffusion-pytorch) (6.0.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate->denoising-diffusion-pytorch) (0.24.7)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate->denoising-diffusion-pytorch) (0.4.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate->denoising-diffusion-pytorch) (2.32.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0->denoising-diffusion-pytorch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate->denoising-diffusion-pytorch) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate->denoising-diffusion-pytorch) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate->denoising-diffusion-pytorch) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate->denoising-diffusion-pytorch) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "import torchvision\n",
        "from torchvision.datasets import MNIST\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from typing import Dict, Generator\n",
        "from torch import Tensor\n",
        "from cv2 import resize"
      ],
      "metadata": {
        "id": "Y5w20xfrs4V4"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_global_seed(seed: int) -> None:\n",
        "    \"\"\"Set global seed for reproducibility.\"\"\"\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_global_seed(42)"
      ],
      "metadata": {
        "id": "VJNmMNn5qe4C"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Определение датасета и предобработки изображений\n",
        "def preprocess_image(image):\n",
        "    image = np.array(image, dtype=np.uint8)\n",
        "    image = resize(image, (32, 32))\n",
        "    return np.array(image, dtype=np.float32) / 127.5 - 1\n",
        "\n",
        "def postprocess_image(image: torch.Tensor) -> torch.Tensor:\n",
        "    image = (image + 1) * 127.5\n",
        "    return torch.clip(image, 0, 255) / 255.0\n",
        "\n",
        "class MnistDataset(Dataset):\n",
        "    def __init__(self, train: bool = True):  # добавлены двойные подчеркивания\n",
        "        super().__init__()\n",
        "        self.mnist = MNIST('data', train=train, download=True)\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.mnist)\n",
        "\n",
        "    def __getitem__(self, index: int) -> Dict[str, Tensor]:\n",
        "        image, target = self.mnist[index]\n",
        "        image = preprocess_image(image)\n",
        "        return {\"images\": torch.tensor(image)[None], \"targets\": target}\n",
        "\n",
        "def dict_to_device(dct: Dict[str, Tensor], device: torch.device) -> Dict[str, Tensor]:\n",
        "    return {k: v.to(device) for k, v in dct.items()}\n",
        "\n",
        "def get_train_images_generator(batch_size: int = 128, num_workers: int = 0, shuffle: bool = True, drop_last: bool = True) -> Generator:\n",
        "    dataset = MnistDataset(train=True)\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers, drop_last=drop_last)\n",
        "    while True:\n",
        "        for batch in dataloader:\n",
        "            yield batch"
      ],
      "metadata": {
        "id": "XiCJRvL1s630"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Подготовка генератора\n",
        "train_generator = get_train_images_generator()"
      ],
      "metadata": {
        "id": "h_pieR6IxbA2"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn, Tensor\n",
        "from typing import Tuple\n",
        "\n",
        "class VPSDEDynamic(nn.Module):\n",
        "    def __init__(self, T=1000, beta_min=0.1, beta_max=20.0):\n",
        "        super().__init__()\n",
        "        self.T = T  # убедитесь, что T сохранен как атрибут объекта\n",
        "        self.beta_min = beta_min\n",
        "        self.beta_max = beta_max\n",
        "        coeffs_primitives = self.get_coeffs_primitives(T, beta_min, beta_max)\n",
        "        for name, tensor in coeffs_primitives.items():\n",
        "            self.register_buffer(name, tensor)\n",
        "\n",
        "    def get_coeffs_primitives(self, T, beta_min, beta_max):\n",
        "        beta_t = torch.linspace(beta_min, beta_max, T)\n",
        "        alpha_t = 1 - beta_t / T\n",
        "        a_t = torch.cumprod(alpha_t, dim=0)\n",
        "        sigma_t = torch.sqrt(1 - a_t**2)\n",
        "        return {\"a_t\": a_t, \"sigma_t\": sigma_t}\n",
        "\n",
        "    def sigma(self, t: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Функция дисперсии для VP-SDE.\n",
        "        \"\"\"\n",
        "        index = t * (self.T - 1)\n",
        "        lower_idx = index.long()\n",
        "        upper_idx = torch.clamp(lower_idx + 1, max=self.T - 1)\n",
        "        weight = index - lower_idx.float()\n",
        "        return torch.lerp(self.sigma_t[lower_idx], self.sigma_t[upper_idx], weight)\n",
        "\n",
        "    def a(self, t: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Функция масштаба для VP-SDE.\n",
        "        \"\"\"\n",
        "        index = t * (self.T - 1)\n",
        "        lower_idx = index.long()\n",
        "        upper_idx = torch.clamp(lower_idx + 1, max=self.T - 1)\n",
        "        weight = index - lower_idx.float()\n",
        "        return torch.lerp(self.a_t[lower_idx], self.a_t[upper_idx], weight)\n",
        "\n",
        "    def sample_time(self, batch_size=1, device=torch.device('cuda:0')):\n",
        "        return torch.rand(batch_size, device=device)\n",
        "\n",
        "    def forward_process(self, x_0: Tensor, t: Tensor) -> Tuple[Tensor, Tensor]:\n",
        "        \"\"\"\n",
        "        Прямой процесс с учетом a(t) и sigma(t).\n",
        "        \"\"\"\n",
        "        a_t = self.a(t).view(-1, 1, 1, 1).expand_as(x_0)\n",
        "        sigma_t = self.sigma(t).view(-1, 1, 1, 1).expand_as(x_0)\n",
        "        noise = torch.randn_like(x_0)  # добавляем случайный шум\n",
        "        x_t = a_t * x_0 + sigma_t * noise\n",
        "        return x_t, noise"
      ],
      "metadata": {
        "id": "17-99nQFtEj2"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Sampler(nn.Module):\n",
        "    def __init__(self, vp_sde: nn.Module, dynamic: VPSDEDynamic):\n",
        "        super().__init__()\n",
        "        self.vp_sde = vp_sde\n",
        "        self.dynamic = dynamic\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def single_step(self, x_t, t):\n",
        "        eps_pred = self.vp_sde(x_t, t)\n",
        "        sigma_t = self.dynamic.sigma(t).view(-1, 1, 1, 1).expand_as(x_t)\n",
        "        a_t = self.dynamic.a(t).view(-1, 1, 1, 1).expand_as(x_t)\n",
        "        noise = torch.randn_like(x_t)\n",
        "        x_t_minus_1 = a_t * x_t - sigma_t * eps_pred + noise * sigma_t\n",
        "        return x_t_minus_1\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def sample(self, shape, device=torch.device('cuda')):\n",
        "        x_t = torch.randn(shape, device=device)\n",
        "        for t in range(self.dynamic.T - 1, -1, -1):\n",
        "            t_tensor = torch.ones(shape[0], dtype=torch.float32, device=device) * t / self.dynamic.T\n",
        "            x_t = self.single_step(x_t, t_tensor)\n",
        "        return x_t"
      ],
      "metadata": {
        "id": "dYl2Enp51eVE"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_ema import ExponentialMovingAverage\n",
        "from tqdm.auto import trange\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "class VPSDETrainer:\n",
        "    def __init__(self, vp_sde, dynamic, device=torch.device('cuda:0')):\n",
        "        self.vp_sde = vp_sde.to(device)\n",
        "        self.dynamic = dynamic.to(device)\n",
        "        self.device = device\n",
        "        self.sampler = Sampler(vp_sde, dynamic)\n",
        "        self.sampler.to(device)\n",
        "        self.ema = ExponentialMovingAverage(vp_sde.parameters(), decay=0.999)\n",
        "        self.optimizer = torch.optim.AdamW(self.vp_sde.parameters(), lr=2e-4, weight_decay=1e-2)\n",
        "\n",
        "    def calc_loss(self, x_0: Tensor) -> Tensor:\n",
        "        batch_size = x_0.size(0)\n",
        "        t = self.dynamic.sample_time(batch_size, device=self.device)\n",
        "        x_t, noise = self.dynamic.forward_process(x_0, t)\n",
        "        eps_pred = self.vp_sde(x_t, t)\n",
        "        return nn.functional.mse_loss(eps_pred, noise)\n",
        "\n",
        "    def train(self, train_generator, total_iters=5000):\n",
        "        self.vp_sde.train()\n",
        "        for iter_idx in trange(1, 1 + total_iters):\n",
        "            batch = next(train_generator)\n",
        "            batch = dict_to_device(batch, self.device)\n",
        "            loss = self.calc_loss(batch[\"images\"])\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "            self.ema.update(self.vp_sde.parameters())\n",
        "\n",
        "            if iter_idx % 500 == 0:\n",
        "                print(f\"Iter {iter_idx}: Loss = {loss.item()}\")\n",
        "\n",
        "        # Сохранение модели после завершения обучения\n",
        "        self.save_model()\n",
        "\n",
        "    def switch_to_ema(self):\n",
        "        \"\"\"Переключение на EMA параметры модели.\"\"\"\n",
        "        self.ema.store(self.vp_sde.parameters())\n",
        "        self.ema.copy_to(self.vp_sde.parameters())\n",
        "\n",
        "    def save_model(self, path=\"vp_sde_model.pth\"):\n",
        "        \"\"\"Сохраняет состояние модели с EMA параметрами.\"\"\"\n",
        "        self.switch_to_ema()\n",
        "        torch.save(self.vp_sde.state_dict(), path)\n",
        "        print(f\"Model saved at {path}\")\n",
        "        self.ema.restore(self.vp_sde.parameters())  # Восстановление после сохранения\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def sample_images(self, batch_size=100):\n",
        "        \"\"\"Генерация изображений.\"\"\"\n",
        "        grid = sample_images(self.sampler, batch_size, self.device)\n",
        "        plt.imshow(grid)\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "    def switch_to_ema(self):\n",
        "        \"\"\"Переключение на EMA параметры модели.\"\"\"\n",
        "        self.ema.store(self.vp_sde.parameters())\n",
        "        self.ema.copy_to(self.vp_sde.parameters())\n",
        "\n",
        "    def save_model(self, path=\"vp_sde_model.pth\"):\n",
        "        \"\"\"Сохраняет состояние модели с EMA параметрами.\"\"\"\n",
        "        self.switch_to_ema()\n",
        "        torch.save(self.vp_sde.state_dict(), path)\n",
        "        print(f\"Model saved at {path}\")\n",
        "        self.ema.restore(self.vp_sde.parameters())  # Восстановление после сохранения\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def sample_images(self, batch_size=100):\n",
        "        \"\"\"Генерация изображений.\"\"\"\n",
        "        grid = sample_images(self.sampler, batch_size, self.device)\n",
        "        plt.imshow(grid)\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "def sample_images(sampler: Sampler, batch_size: int = 100, device=torch.device('cuda')):\n",
        "    images = sampler.sample((batch_size, 1, 32, 32), device=device)\n",
        "    images = postprocess_image(images)\n",
        "    images = images.cpu()\n",
        "    nrow = int(math.ceil(math.sqrt(batch_size)))\n",
        "    grid = torchvision.utils.make_grid(images, nrow=nrow).permute(1, 2, 0)\n",
        "    grid = grid.data.numpy().astype(np.uint8)\n",
        "    return grid"
      ],
      "metadata": {
        "id": "RmBDn410trla"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def postprocess_image(image: torch.Tensor) -> torch.Tensor:\n",
        "    image = (image + 1) * 127.5  # Приводим к диапазону [0, 255]\n",
        "    image = torch.clip(image, 0, 255) / 255.0  # Приводим к [0, 1] для matplotlib\n",
        "    return image"
      ],
      "metadata": {
        "id": "qTwiuthqIAG1"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Определение модели UNet\n",
        "from denoising_diffusion_pytorch import Unet\n",
        "\n",
        "vp_sde = Unet(dim=64, dim_mults=(1, 2, 4, 4), channels=1)\n",
        "\n",
        "dynamic = VPSDEDynamic()\n",
        "\n"
      ],
      "metadata": {
        "id": "LmHcmuZ02IKc"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Инициализация и запуск тренировки\n",
        "trainer = VPSDETrainer(vp_sde, dynamic, device=torch.device('cuda:0'))\n",
        "trainer.train(train_generator, total_iters=5000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240,
          "referenced_widgets": [
            "9d949fc3f1bb4624adf1b97f6ef01dea",
            "2aa39c8b6d984c00bccb543223679741",
            "f138ca271a7a43b6b1ad26922c059289",
            "b81e4a61a98145f4b9096b3bba7b62fd",
            "bd987978bdc34d56b004fd3575f01f14",
            "931e16dd3eb0426b914d72bc2480de83",
            "2db6adce78934e0e9bb6b4c1157e9603",
            "dd712e7ea6984d5382756d368d77a599",
            "516fa8700cc34bb0b9df44b2db0d0768",
            "c723a55c9af343b3bcc30fe0ca6f8211",
            "658fd08515d74c14992a78b3fb96b362"
          ]
        },
        "id": "bWAz_p7g1gN0",
        "outputId": "ea1ad027-c83a-4f28-d096-2c85d3e1be3a"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9d949fc3f1bb4624adf1b97f6ef01dea"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 500: Loss = 0.01352410763502121\n",
            "Iter 1000: Loss = 0.011541744694113731\n",
            "Iter 1500: Loss = 0.012308033183217049\n",
            "Iter 2000: Loss = 0.015861360356211662\n",
            "Iter 2500: Loss = 0.011455483734607697\n",
            "Iter 3000: Loss = 0.012320625595748425\n",
            "Iter 3500: Loss = 0.00863692071288824\n",
            "Iter 4000: Loss = 0.010694175958633423\n",
            "Iter 4500: Loss = 0.008411324582993984\n",
            "Iter 5000: Loss = 0.0119339469820261\n",
            "Model saved at vp_sde_model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.sample_images(batch_size=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "wwlzyZheAM6B",
        "outputId": "6e74d459-7d9a-4b0c-c225-05af45b91b53"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}